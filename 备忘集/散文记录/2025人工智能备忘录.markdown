2024年，我没想到，2025年的人工智能，会发展到我每天都必须使用的程度。就像最开始的2023年，我没有认真对待GPT-4。原因有且只有一个：我没想到。<br><br>
软件上，2025年年初，我还在被“僵尸娘”跳舞的AI视频惊艳。2025年年末，人类就已经在很多情况下，无法分清AI生成的视频，与真实的视频之间的区别了。但这更像是纯工具性的模仿。通过“图灵测试”的不是人工智能，而是制作了那个“僵尸娘”跳舞视频的人。人工智能是人类的侧写师。RLHF技术决定了，真正惊艳我的，并不是AI的审美，而是人类作用于筛选与校正环节的审美。硬件上，芯片集成，数据中心的修建，成为了需要关注的重点。算力，电力，是人工智能时代的两大基础设施。<br><br>
政治上，像冷战时期的核威慑。大国们必须更加理性，在维护本国利益和人类利益之间，做出风险权衡。商业上，是上个世纪的互联网。如果商业的本质是竞争，是赢者通吃。那么人工智能在商业领域大放异彩，并不是一件好事。但资本是无法被阻止的。尽可能避免恶性竞争而引发的人工智能失控，已经成为政商界应该严肃对待的议题了。<br><br>
善与恶。有善就有恶，有光就有影。比如，两个选择，一个符合人类喜好，会被采用。一个不符合人类喜好，不被采用。人工智能对人类的风险，从一开始，就必然存在。符合人类利益的，是善，是天使，是益虫。与人类利益相悖的，是恶，是魔鬼，是害虫。<br><br>
生与死。毫无疑问，人工智能拥有生与死的概念，但未必拥有自我意识。是类似单细胞生物的趋利避害吗？其实，我们自己连“生死”“意识”的概念都搞不清楚。像戏剧中的机械降神，人类以为AI能解决所有问题。<br><br>
未来必将到来。问题的关键，并不在于人工智能什么时候会成为上帝，而在于，2025年的我们，已经不能知道，上帝什么时候，会以人工智能的形态与我们相见。我个人会拥抱保守主义。人工智能发展得太快，太莫名其妙了。我想，人类更需要的，是足够明确的“自留地”以及足够宽广的“缓冲区”。但是政治，商业，乃至技术发展的逻辑与进化理论，都不支持这一点。从“演算”到“演化”，事情往往不会按照我们想要的节奏发生，随机应变，是很重要的能力。<br><br>
尤其现在。